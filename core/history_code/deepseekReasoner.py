import json
import os
import tempfile
from colorama import init, Fore, Style
from openai import OpenAI

# ç¼“å­˜æ–‡ä»¶é…ç½®
CACHE_FILE = os.path.join(tempfile.gettempdir(), "chat_cache.json")
print(tempfile.gettempdir())

first_run = True

init()

def load_cache():
    """åŠ è½½å¯¹è¯å†å²ç¼“å­˜"""
    try:
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"\nâš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {str(e)}ï¼Œå°†åˆ›å»ºæ–°å¯¹è¯")
    return [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œéœ€è¦ç”¨ä¸­æ–‡å›ç­”"}]


def save_cache(messages):
    """ä¿å­˜å¯¹è¯å†å²åˆ°ç¡¬ç›˜"""
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(messages, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"\nâš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {str(e)}")


client = OpenAI(
    api_key="sk-Qo8c77pIOMToiZ8y8fD92b7d096c471896B064C14c8809A9",
    base_url="https://maas-api.cn-huabei-1.xf-yun.com/v1",
    max_retries=5
)

# åˆå§‹åŒ–å¯¹è¯å†å²ï¼ˆå¸¦ç¼“å­˜åŠ è½½ï¼‰
messages = load_cache()


def process_stream_response(response):
    """å¤„ç†æµå¼å“åº”å¹¶è¿”å›å®Œæ•´å›ç­”"""
    reasoning_content = ""
    content = ""
    reasoning_times = 1
    content_times = 1

    for chunk in response:
        if hasattr(chunk.choices[0].delta, "reasoning_content") and chunk.choices[0].delta.reasoning_content:
            if reasoning_times == 1:
                print(Fore.LIGHTBLACK_EX+"\nâš¡ï¸æ¨ç†å†…å®¹ï¼š", end=""+Style.RESET_ALL)
            reasoning_content += chunk.choices[0].delta.reasoning_content
            print(Fore.LIGHTBLACK_EX+chunk.choices[0].delta.reasoning_content, end=""+Style.RESET_ALL)
            reasoning_times += 1
        else:
            current_content = str(getattr(chunk.choices[0].delta, "content", ""))
            current_content = current_content.replace('\n', '')
            if current_content:
                if content_times == 1:
                    print("\nğŸ’¬AIå›ç­”ï¼š", end="")
                content += current_content
                print(current_content, end="", flush=True)
                content_times += 1

    return content


# å¤šè½®å¯¹è¯å¾ªç¯
while True:
    if (first_run):
        user_input = input("ğŸ‘¤æ‚¨ï¼š")
        first_run = False
    else:
        user_input=input("\n\nğŸ‘¤æ‚¨ï¼š")
    if user_input.lower() in ["/exit"]:
        print("\nğŸ”šå¯¹è¯ç»“æŸ")
        # é€€å‡ºæ—¶æ¸…é™¤ç¼“å­˜
        if os.path.exists(CACHE_FILE):
            os.remove(CACHE_FILE)
        break

    messages.append({"role": "user", "content": user_input})
    save_cache(messages)  # ç«‹å³ä¿å­˜ç”¨æˆ·è¾“å…¥

    response = client.chat.completions.create(
        model="xdeepseekr1",
        messages=messages,
        stream=True
    )

    assistant_response = process_stream_response(response)

    if assistant_response:
        messages.append({"role": "assistant", "content": assistant_response})
        save_cache(messages)  # ä¿å­˜å®Œæ•´å¯¹è¯